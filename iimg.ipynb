{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6fd929a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- æ­£åœ¨åˆå§‹åŒ–é…ç½® ---\n",
      "\n",
      "--- æ­£åœ¨åŠ è½½æ¨¡å‹ (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´) ---\n",
      "ä½¿ç”¨çš„è®¾å¤‡: cuda\n",
      "æ­£åœ¨åŠ è½½ CLIP æ¨¡å‹...\n",
      "âœ… CLIP æ¨¡å‹åŠ è½½å®Œæˆï¼\n",
      "æ­£åœ¨åŠ è½½ DeepDanbooru ONNX æ¨¡å‹...\n",
      "âœ… DeepDanbooru æ¨¡å‹åŠ è½½å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoProcessor, CLIPModel\n",
    "from deepdanbooru_onnx import DeepDanbooru, process_image\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "danbooru = DeepDanbooru()\n",
    "# ==============================================================================\n",
    "# ### ç¬¬ 0 éƒ¨åˆ†: å…¨å±€é…ç½® ###\n",
    "# ==============================================================================\n",
    "print(\"--- æ­£åœ¨åˆå§‹åŒ–é…ç½® ---\")\n",
    "\n",
    "\n",
    "# --- ç­›é€‰é˜ˆå€¼é…ç½® ---\n",
    "# CLIPæ¨¡å‹åˆ¤æ–­ä¸ºâ€œçœŸäººâ€çš„ç½®ä¿¡åº¦é˜ˆå€¼ (0.0 - 1.0, è¶Šé«˜è¶Šä¸¥æ ¼)\n",
    "# DeepDanbooru åˆ¤æ–­ä¸º NSFW çš„åˆ†æ•°é˜ˆå€¼ (0.0 - 1.0)\n",
    "NSFW_THRESHOLD = 0.4\n",
    "# è´¨é‡ç­›é€‰ï¼šå›¾ç‰‡æœ€å°å°ºå¯¸\n",
    "MIN_WIDTH = 512\n",
    "MIN_HEIGHT = 512\n",
    "MIN_TOTAL_PIXELS = 0 # æœ€å°æ€»åƒç´ ï¼Œ0è¡¨ç¤ºä¸å¯ç”¨\n",
    "\n",
    "# --- å…¶ä»–é…ç½® ---\n",
    "SUPPORTED_FORMATS = ('.png', '.jpg', '.jpeg', '.bmp', '.webp')\n",
    "\n",
    "# ==============================================================================\n",
    "# ### ç¬¬ 1 éƒ¨åˆ†: åˆå§‹åŒ–ã€åŠ è½½æ¨¡å‹ä¸å‡†å¤‡æ–‡ä»¶å¤¹ ###\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1.1 æ¨¡å‹åŠ è½½ ---\n",
    "print(\"\\n--- æ­£åœ¨åŠ è½½æ¨¡å‹ (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´) ---\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ä½¿ç”¨çš„è®¾å¤‡: {DEVICE}\")\n",
    "\n",
    "# åŠ è½½ CLIP æ¨¡å‹\n",
    "clip_model = None\n",
    "clip_processor = None\n",
    "try:\n",
    "    print(\"æ­£åœ¨åŠ è½½ CLIP æ¨¡å‹...\")\n",
    "    CLIP_MODEL_ID = \"openai/clip-vit-base-patch32\"\n",
    "    clip_processor = AutoProcessor.from_pretrained(CLIP_MODEL_ID)\n",
    "    # ä½¿ç”¨ use_safetensors=True æ¥é¿å… torch.load çš„å®‰å…¨æ¼æ´é—®é¢˜\n",
    "    clip_model = CLIPModel.from_pretrained(CLIP_MODEL_ID, use_safetensors=True).to(DEVICE)\n",
    "    print(\"âœ… CLIP æ¨¡å‹åŠ è½½å®Œæˆï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åŠ è½½ CLIP æ¨¡å‹å¤±è´¥ï¼é”™è¯¯: {e}\")\n",
    "    traceback.print_exc()\n",
    "    # å¦‚æœæ ¸å¿ƒæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåˆ™æ— æ³•ç»§ç»­ï¼Œé€€å‡ºç¨‹åº\n",
    "    exit()\n",
    "\n",
    "# åŠ è½½ DeepDanbooru æ¨¡å‹\n",
    "danbooru = None\n",
    "try:\n",
    "    print(\"æ­£åœ¨åŠ è½½ DeepDanbooru ONNX æ¨¡å‹...\")\n",
    "    danbooru = DeepDanbooru()\n",
    "    print(\"âœ… DeepDanbooru æ¨¡å‹åŠ è½½å®Œæˆï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åŠ è½½ DeepDanbooru æ¨¡å‹å¤±è´¥ï¼é”™è¯¯: {e}\")\n",
    "    traceback.print_exc()\n",
    "    exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3928f4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- æ­£åœ¨å‡†å¤‡æ–‡ä»¶å¤¹ç»“æ„ ---\n",
      "âœ… æ–‡ä»¶å¤¹å‡†å¤‡å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "# å‡è®¾ä½ çš„æ¨¡å‹å’Œå¤„ç†å™¨å·²ç»åŠ è½½å¥½äº†ï¼Œä¾‹å¦‚ï¼š\n",
    "# from transformers import CLIPProcessor, CLIPModel\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(DEVICE)\n",
    "# clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "# --- è·¯å¾„å’Œå‚æ•°é…ç½® (è¯·æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹) ---\n",
    "SOURCE_FOLDER = r'F:\\sese\\å›¾åŒ…\\photos'\n",
    "DESTINATION_BASE_FOLDER = r'F:\\sese\\å›¾åŒ…\\photos'\n",
    "\n",
    "# --- æ–°å¢ï¼šæ‰¹å¤„ç†å¤§å° ---\n",
    "# BATCH_SIZEå¯ä»¥æ ¹æ®ä½ çš„GPUæ˜¾å­˜è¿›è¡Œè°ƒæ•´ã€‚32æˆ–64æ˜¯å¸¸è§çš„èµ·å§‹å€¼ã€‚\n",
    "# å¦‚æœé‡åˆ° \"CUDA out of memory\" é”™è¯¯ï¼Œè¯·è°ƒä½æ­¤æ•°å€¼ã€‚\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- å›¾ç‰‡è´¨é‡é…ç½® ---\n",
    "MIN_WIDTH = 512\n",
    "MIN_HEIGHT = 512\n",
    "MIN_TOTAL_PIXELS = MIN_WIDTH * MIN_HEIGHT\n",
    "SUPPORTED_FORMATS = ('.png', '.jpg', '.jpeg', '.webp', '.bmp')\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ### å‡†å¤‡å·¥ä½œ (ä¸åŸä»£ç ç›¸åŒ) ###\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1.2 æ–‡ä»¶å¤¹å‡†å¤‡ ---\n",
    "print(\"\\n--- æ­£åœ¨å‡†å¤‡æ–‡ä»¶å¤¹ç»“æ„ ---\")\n",
    "real_folder = os.path.join(DESTINATION_BASE_FOLDER, 'çœŸäºº')\n",
    "anime_folder = os.path.join(DESTINATION_BASE_FOLDER, 'åŠ¨æ¼«')\n",
    "anime_normal_folder = os.path.join(anime_folder, 'normal')\n",
    "anime_nsfw_folder = os.path.join(anime_folder, 'nsfw')\n",
    "low_quality_folder = os.path.join(DESTINATION_BASE_FOLDER, 'low_quality')\n",
    "error_folder = os.path.join(DESTINATION_BASE_FOLDER, 'error')\n",
    "more_folder = os.path.join(DESTINATION_BASE_FOLDER, 'æ‚é¡¹')\n",
    "TEMP_ANIME_FOLDER = os.path.join(DESTINATION_BASE_FOLDER, '_temp_anime_processing')\n",
    "\n",
    "all_folders_to_create = [\n",
    "    real_folder, anime_normal_folder, anime_nsfw_folder,\n",
    "    low_quality_folder, error_folder, TEMP_ANIME_FOLDER,more_folder\n",
    "]\n",
    "for folder in all_folders_to_create:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "print(\"âœ… æ–‡ä»¶å¤¹å‡†å¤‡å®Œæˆï¼\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d490bebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- (é˜¶æ®µ 1/2) å¼€å§‹ä½¿ç”¨ CLIP è¿›è¡Œä¸€çº§åˆ†ç±» (æ‰¹å¤„ç†ä¼˜åŒ–) ---\n",
      "åœ¨æºæ–‡ä»¶å¤¹ä¸­å‘ç° 32547 ä¸ªå¾…å¤„ç†çš„å›¾ç‰‡æ–‡ä»¶ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLIP åˆ†ç±»æ‰¹å¤„ç†: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1018/1018 [20:34<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CLIP ä¸€çº§åˆ†ç±»å®Œæˆï¼\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# ### ç¬¬ 2 éƒ¨åˆ†: ä½¿ç”¨ CLIP è¿›è¡Œä¸€çº§åˆ†ç±» (æ‰¹å¤„ç†ä¼˜åŒ–ç‰ˆ) ###\n",
    "# ==============================================================================\n",
    "print(\"\\n--- (é˜¶æ®µ 1/2) å¼€å§‹ä½¿ç”¨ CLIP è¿›è¡Œä¸€çº§åˆ†ç±» (æ‰¹å¤„ç†ä¼˜åŒ–) ---\")\n",
    "\n",
    "if not os.path.isdir(SOURCE_FOLDER):\n",
    "    print(f\"âŒ è‡´å‘½é”™è¯¯ï¼šæºæ–‡ä»¶å¤¹ '{SOURCE_FOLDER}' ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚\")\n",
    "else:\n",
    "    image_files = [f for f in os.listdir(SOURCE_FOLDER) if os.path.isfile(os.path.join(SOURCE_FOLDER, f)) and f.lower().endswith(SUPPORTED_FORMATS)]\n",
    "    print(f\"åœ¨æºæ–‡ä»¶å¤¹ä¸­å‘ç° {len(image_files)} ä¸ªå¾…å¤„ç†çš„å›¾ç‰‡æ–‡ä»¶ã€‚\")\n",
    "\n",
    "    clip_text_prompts = [\n",
    "        \"a high-resolution photograph of a real person, a real life scene, realistic photo, dslr quality\",\n",
    "        \"anime style drawing, illustration, digital art, character art, manga, cartoon, 2d art\"\n",
    "    ]\n",
    "\n",
    "    # --- æ‰¹å¤„ç†å¾ªç¯ ---\n",
    "    # æˆ‘ä»¬å°† image_files åˆ—è¡¨æŒ‰ BATCH_SIZE åˆ†å—å¤„ç†\n",
    "    for i in tqdm(range(0, len(image_files), BATCH_SIZE), desc=\"CLIP åˆ†ç±»æ‰¹å¤„ç†\"):\n",
    "        # è·å–å½“å‰æ‰¹æ¬¡çš„\n",
    "        batch_filenames = image_files[i:i + BATCH_SIZE]\n",
    "        \n",
    "        # ç”¨äºå­˜å‚¨å½“å‰æ‰¹æ¬¡ä¸­é€šè¿‡äº†è´¨é‡æ£€æŸ¥çš„å›¾ç‰‡å’Œå…¶åŸå§‹è·¯å¾„\n",
    "        batch_images_for_clip = []\n",
    "        batch_source_paths = []\n",
    "\n",
    "        # 1. é¢„å¤„ç†å½“å‰æ‰¹æ¬¡ï¼šåŠ è½½ã€æ£€æŸ¥è´¨é‡\n",
    "        for filename in batch_filenames:\n",
    "            image_path = os.path.join(SOURCE_FOLDER, filename)\n",
    "            destination_path=None\n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    # è´¨é‡æ£€æŸ¥\n",
    "                    width, height = img.size\n",
    "                    \n",
    "                    if width < MIN_WIDTH or height < MIN_HEIGHT :\n",
    "                        destination_path = os.path.join(low_quality_folder, filename)\n",
    "                        \n",
    "                    else:\n",
    "                        img_rgb = img.convert(\"RGB\")\n",
    "                        batch_images_for_clip.append(img_rgb)\n",
    "                        batch_source_paths.append(image_path)\n",
    "            except Exception as e:\n",
    "                shutil.move(image_path, error_folder)\n",
    "            if destination_path:\n",
    "                shutil.move(image_path, destination_path)\n",
    "\n",
    "        \n",
    "        # 2. å¯¹æ•´ä¸ªæ‰¹æ¬¡è¿›è¡ŒCLIPåˆ†ç±» (å¦‚æœæ‰¹æ¬¡ä¸­æœ‰æœ‰æ•ˆå›¾ç‰‡)\n",
    "        if not batch_images_for_clip:\n",
    "            continue # å¦‚æœå½“å‰æ‰¹æ¬¡æ‰€æœ‰å›¾ç‰‡éƒ½æ˜¯ä½è´¨é‡æˆ–é”™è¯¯ï¼Œåˆ™è·³è¿‡\n",
    "\n",
    "        #try:\n",
    "        with torch.no_grad():\n",
    "            # ä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ªæ‰¹æ¬¡çš„å›¾ç‰‡\n",
    "            inputs = clip_processor(\n",
    "                text=clip_text_prompts, \n",
    "                images=batch_images_for_clip, \n",
    "                return_tensors=\"pt\", \n",
    "                padding=True\n",
    "            ).to(DEVICE)\n",
    "            \n",
    "            outputs = clip_model(**inputs)\n",
    "            # `probs` ç°åœ¨æ˜¯ä¸€ä¸ªå¼ é‡ï¼Œæ¯è¡Œå¯¹åº”ä¸€æ‰¹æ¬¡ä¸­çš„ä¸€å¼ å›¾ç‰‡\n",
    "            probs = outputs.logits_per_image.softmax(dim=1)\n",
    "\n",
    "        # 3. æ ¹æ®æ‰¹å¤„ç†ç»“æœï¼Œç§»åŠ¨æ–‡ä»¶\n",
    "        for idx, source_path in enumerate(batch_source_paths):\n",
    "            prob_real = probs[idx][0].item()\n",
    "            filename = os.path.basename(source_path)\n",
    "            \n",
    "            if prob_real >= 0.5:\n",
    "                destination_path = os.path.join(real_folder, filename)\n",
    "            else:\n",
    "                destination_path = os.path.join(TEMP_ANIME_FOLDER, filename) \n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "        #except Exception as e:\n",
    "        #    print(f\"å¤„ç†æ‰¹æ¬¡ {i//BATCH_SIZE + 1} æ—¶å‘ç”Ÿæ¨¡å‹é”™è¯¯: {e}\")\n",
    "        #    # å¦‚æœæ¨¡å‹åœ¨æ•´ä¸ªæ‰¹æ¬¡ä¸Šå¤±è´¥ï¼Œå°è¯•å°†è¿™ä¸ªæ‰¹æ¬¡çš„æ–‡ä»¶ç§»åˆ°é”™è¯¯æ–‡ä»¶å¤¹\n",
    "        #    for source_path in batch_source_paths:\n",
    "        #        try:\n",
    "        #            shutil.move(source_path, os.path.join(error_folder, os.path.basename(source_path)))\n",
    "        #        except Exception as move_e:\n",
    "        #            print(f\"ç§»åŠ¨æ–‡ä»¶ {os.path.basename(source_path)} åˆ° 'error' æ–‡ä»¶å¤¹å¤±è´¥: {move_e}\")\n",
    "\n",
    "    print(\"âœ… CLIP ä¸€çº§åˆ†ç±»å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a11b5b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- (é˜¶æ®µ 2/2) å¼€å§‹ä½¿ç”¨ DeepDanbooru å¯¹åŠ¨æ¼«å›¾ç‰‡è¿›è¡ŒäºŒçº§åˆ†ç±» ---\n",
      "å‘ç° 31859 ä¸ªå¾…å¤„ç†çš„åŠ¨æ¼«å›¾ç‰‡ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepDanbooru åˆ†ç±»è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31859/31859 [3:36:29<00:00,  2.45it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¸…ç†ç©ºçš„ä¸´æ—¶æ–‡ä»¶å¤¹...\n",
      "\n",
      "ğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰å¤„ç†æµç¨‹å®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- (é˜¶æ®µ 2/2) å¼€å§‹ä½¿ç”¨ DeepDanbooru å¯¹åŠ¨æ¼«å›¾ç‰‡è¿›è¡ŒäºŒçº§åˆ†ç±» ---\")\n",
    "nsfw_keys = [\n",
    "    # èº«ä½“éƒ¨ä½\n",
    "    'breasts',       # èƒ¸éƒ¨\n",
    "    'cleavage',      # ä¹³æ²Ÿ\n",
    "    'ass',           # è‡€éƒ¨\n",
    "    'navel',         # è‚šè„\n",
    "    'nipples',       # ä¹³å¤´\n",
    "    'pussy',         # é˜´éƒ¨\n",
    "    'armpits',       # è…‹çª\n",
    "    'thighs',        # å¤§è…¿\n",
    "    'groin',         # è…¹è‚¡æ²Ÿ\n",
    "    'sideboob',      # ä¾§ä¹³\n",
    "    'female_pubic_hair',  # å¥³æ€§é˜´æ¯›\n",
    "    'pubic_hair',    # é˜´æ¯›\n",
    "    'large_breasts', # å¤§èƒ¸\n",
    "    'butt_crack',    # è‡€ç¼\n",
    "    \n",
    "    # å§¿åŠ¿/çŠ¶æ€\n",
    "    'spread_legs',   # å¼ å¼€åŒè…¿\n",
    "    'bent_over',     # å¼¯è…°\n",
    "    'from_behind',   # ä»åé¢\n",
    "    'on_back',       # ä»°å§\n",
    "    'on_stomach',    # ä¿¯å§\n",
    "    'lying',         # èººç€\n",
    "    'open_clothes',  # æ•å¼€çš„è¡£æœ\n",
    "    'strap_slip',    # è‚©å¸¦æ»‘è½\n",
    "    \n",
    "    # è¡£ç‰©/ç‰©å“\n",
    "    'underwear',     # å†…è¡£\n",
    "    'panties',       # å†…è£¤\n",
    "    'bra',           # èƒ¸ç½©\n",
    "    'pasties',       # ä¹³è´´\n",
    "    'torn_clothes',  # ç ´æŸçš„è¡£æœ\n",
    "    'condom_wrapper',# é¿å­•å¥—åŒ…è£…\n",
    "    \n",
    "    # è¡Œä¸º/çŠ¶æ€\n",
    "    'lactation',     # å“ºä¹³\n",
    "    'prostitution',  # å–æ·«\n",
    "    'uncensored',    # æ— ç \n",
    "    'nude',          # è£¸ä½“\n",
    "    'nude_cover',    # è£¸ä½“é®ç›–\n",
    "    \n",
    "    # è¯„çº§æ ‡ç­¾\n",
    "    'rating:questionable',  # å¯ç–‘è¯„çº§\n",
    "    'rating:nsfw',          # NSFWè¯„çº§\n",
    "    \n",
    "    # å¯ç»§ç»­æ·»åŠ çš„æ ‡ç­¾...\n",
    "]\n",
    "if not os.path.isdir(TEMP_ANIME_FOLDER):\n",
    "    print(f\"âš ï¸ è­¦å‘Šï¼šä¸´æ—¶æ–‡ä»¶å¤¹ '{TEMP_ANIME_FOLDER}' æœªæ‰¾åˆ°ï¼Œå¯èƒ½æ²¡æœ‰éœ€è¦äºŒæ¬¡å¤„ç†çš„å›¾ç‰‡ã€‚\")\n",
    "else:\n",
    "    anime_files = [f for f in os.listdir(TEMP_ANIME_FOLDER) if os.path.isfile(os.path.join(TEMP_ANIME_FOLDER, f)) and f.lower().endswith(SUPPORTED_FORMATS)]\n",
    "    if not anime_files:\n",
    "        print(\"âœ… ä¸´æ—¶æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰éœ€è¦å¤„ç†çš„åŠ¨æ¼«å›¾ç‰‡ã€‚\")\n",
    "    else:\n",
    "        print(f\"å‘ç° {len(anime_files)} ä¸ªå¾…å¤„ç†çš„åŠ¨æ¼«å›¾ç‰‡ã€‚\")\n",
    "        for filename in tqdm(anime_files, desc=\"DeepDanbooru åˆ†ç±»è¿›åº¦\"):\n",
    "            image_path = os.path.join(TEMP_ANIME_FOLDER, filename)\n",
    "            img=[image_path]\n",
    "            destination_path = None\n",
    "            results = list(danbooru(img))\n",
    "            if results[0].get('1girl',0.0)+results[0].get('2girls',0.0)<0.5:\n",
    "                shutil.move(image_path,more_folder)\n",
    "                continue\n",
    "            try:\n",
    "                nsfw_score = max(results[0].get(key, 0.0) for key in nsfw_keys)\n",
    "                #print(nsfw_score)\n",
    "                if nsfw_score > 0.6:\n",
    "                    destination_path=anime_nsfw_folder\n",
    "                else:\n",
    "                    destination_path=anime_normal_folder\n",
    "                shutil.move(image_path, destination_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e} \")\n",
    "                try:\n",
    "                    shutil.move(image_path,error_folder)\n",
    "                except Exception as move_e:\n",
    "                    print(f\"ç§»åŠ¨æ–‡ä»¶ {filename} åˆ° 'error' æ–‡ä»¶å¤¹ä¹Ÿå¤±è´¥äº†: {move_e}\")\n",
    "    \n",
    "    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹\n",
    "    try:\n",
    "        if os.path.exists(TEMP_ANIME_FOLDER) and not os.listdir(TEMP_ANIME_FOLDER):\n",
    "            print(\"æ¸…ç†ç©ºçš„ä¸´æ—¶æ–‡ä»¶å¤¹...\")\n",
    "            os.rmdir(TEMP_ANIME_FOLDER)\n",
    "    except OSError as e:\n",
    "        print(f\"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹å¤±è´¥: {e}\")\n",
    "\n",
    "print(\"\\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰å¤„ç†æµç¨‹å®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
